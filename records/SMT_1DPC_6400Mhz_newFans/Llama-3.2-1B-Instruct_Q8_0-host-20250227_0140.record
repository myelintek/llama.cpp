./build/bin/llama-bench -m ~/.cache/llama.cpp/Llama-3.2-1B-Instruct_Q8_0.gguf             -p 512,1024             -n 128,256             -t 64,128             --delay 0             -r 50             --cpu-strict 1             --mmap 0
begin
Thu Feb 27 03:36:39 AM UTC 2025
| model                          |       size |     params | backend    | threads | cpu_strict | mmap |          test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | ---------: | ---: | ------------: | -------------------: |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |      64 |          1 |    0 |         pp512 |     1224.37 ± 175.25 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |      64 |          1 |    0 |        pp1024 |     1280.37 ± 160.45 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |      64 |          1 |    0 |         tg128 |        157.96 ± 3.17 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |      64 |          1 |    0 |         tg256 |        166.70 ± 2.06 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |     128 |          1 |    0 |         pp512 |     1221.57 ± 270.39 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |     128 |          1 |    0 |        pp1024 |      884.50 ± 436.87 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |     128 |          1 |    0 |         tg128 |        94.82 ± 38.50 |
| llama 1B Q8_0                  |   1.22 GiB |     1.24 B | CPU        |     128 |          1 |    0 |         tg256 |       106.40 ± 37.98 |

build: 9626d935 (4741)
Thu Feb 27 03:45:36 AM UTC 2025
end
